# Intel Image Classification (EfficientNet-B0)

A professional image classification project built using **PyTorch** and **EfficientNet-B0 (ImageNet pretrained)** on the **Intel Scene Classification dataset**.

This repository follows a clean, scalable architecture inspired by real-world deep learning projects and is suitable for freelance, production, and research use cases.

---

## ğŸ“Œ Project Overview

- **Dataset:** Intel Image Classification (Kaggle)
- **Task:** Scene classification
- **Framework:** PyTorch
- **Model:** EfficientNet-B0 (pretrained on ImageNet)
- **Train / Validation Split:** 80 / 20
- **Evaluation Metrics:**
  - Accuracy
  - Confusion Matrix
  - Classification Report

---

## ğŸ“‚ Dataset Structure

The project expects the following dataset structure (default Kaggle paths):
```
seg_train/seg_train/
seg_test/seg_test/
seg_pred/seg_pred/ (optional)

```

Dataset source:  
**Kaggle â€“ puneet6060/intel-image-classification**

---

## ğŸ§  Model & Training Strategy

- EfficientNet-B0 with ImageNet pretrained weights
- Configurable fine-tuning modes:
  - `feature_extraction` (classifier only)
  - `fine_tune` (classifier + last feature blocks)
  - `full` (entire model)
- Loss Function: Cross Entropy Loss
- Optimizer: Adam
- Learning Rate Scheduler: ReduceLROnPlateau
- Early Stopping based on validation loss

---

## ğŸ— Project Structure

```
intel-image-classification/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data.py # Data loading & transforms
â”‚ â”œâ”€â”€ model.py # EfficientNet-B0 definition
â”‚ â”œâ”€â”€ engine.py # Training & validation loops
â”‚ â””â”€â”€ train.py # Training orchestration script
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ intel_image_classification_full.ipynb # Self-contained notebook
â”‚
â”œâ”€â”€ configs/
â”‚ â””â”€â”€ config.yaml # Training & experiment configuration
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


---

## ğŸ““ Notebook

A **self-contained Jupyter Notebook** is provided:

```
notebooks/intel_image_classification_full.ipynb
```


âœ” Includes **all code** (data, model, training, evaluation)  
âœ” No dependency on `src/` files  
âœ” Ideal for reviewers, clients, and demonstrations  

---

## ğŸš€ Training Script

The main training pipeline is implemented in:

```
src/train.py
```


It orchestrates:
- Data loading
- Model initialization
- Training & validation
- Checkpoint saving
- Evaluation & reporting

---

## ğŸ“Š Outputs

Training artifacts are automatically saved under:

```
outputs/
â”œâ”€â”€ checkpoints/
â”‚ â””â”€â”€ efficientnet_b0_intel_best.pth
â”‚
â”œâ”€â”€ figures/
â”‚ â”œâ”€â”€ training_curves.png
â”‚ â””â”€â”€ confusion_matrix.png
â”‚
â””â”€â”€ reports/
â””â”€â”€ classification_report.txt
```

---

## âš™ Configuration

All experiment settings are centralized in:

```
configs/config.yaml
```

This includes:
- Dataset paths
- Image preprocessing
- Training hyperparameters
- Scheduler settings
- Output directories
- Random seed

---

## ğŸ“¦ Installation

Install dependencies using:

```bash
pip install -r requirements.txt
```
Author
Mohamed Fathy


